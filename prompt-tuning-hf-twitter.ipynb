{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/peft/main/en/task_guides/clm-prompt-tuning"
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_name_or_path = \"bigscience/bloomz-560m\"\n",
    "tokenizer_name_or_path = model_name_or_path\n",
    "\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "    num_virtual_tokens=8,\n",
    "    prompt_tuning_init_text=\"Classify if the tweet is a complaint or not\",\n",
    "    tokenizer_name_or_path=tokenizer_name_or_path,\n",
    ")\n",
    "\n",
    "dataset_name = \"twitter_complaints\"\n",
    "checkpoint_name = f\"{dataset_name}_{model_name_or_path}_{peft_config.peft_type}_{peft_config.task_type}_v1.pt\".replace(\"/\", \"_\")\n",
    "text_column = \"Tweet text\"\n",
    "label_column = \"text_label\"\n",
    "max_length = 64\n",
    "lr = 3e-2\n",
    "num_epochs = 50\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ought/raft\", dataset_name)\n",
    "\n",
    "#{\"Tritter text\": \"@HMRCcustomers No this is my first job\", \"ID\": 0, \"Label\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [k.replace(\"_\", \" \") for k in dataset[\"train\"].features[\"Label\"].names]\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [classes[label] for label in x[\"Label\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tweet text': \"If I can't get my 3rd pair of @beatsbydre powerbeats to work today I'm doneski man. This is a slap in my balls. Your next @Bose @BoseService\",\n",
       " 'ID': 2,\n",
       " 'Label': 1,\n",
       " 'text_label': 'complaint'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "target_max_length = max([len(tokenizer(class_label)[\"input_ids\"]) for class_label in classes])\n",
    "print(target_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tweet text': '@HMRCcustomers No this is my first job', 'ID': 0, 'Label': 2, 'text_label': 'no complaint'}\n"
     ]
    }
   ],
   "source": [
    "print((dataset[\"train\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no complaint\n"
     ]
    }
   ],
   "source": [
    "token_ids = [1936, 106863]  # replace with your token IDs\n",
    "token_text = tokenizer.decode(token_ids)\n",
    "print(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[text_column])\n",
    "    inputs = [f\"{text_column} : {x} Label : \" for x in examples[text_column]]\n",
    "    targets = [str(x) for x in examples[label_column]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(targets)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.pad_token_id]\n",
    "        # print(i, sample_input_ids, label_input_ids)\n",
    "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "    # print(model_inputs)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "            \"attention_mask\"\n",
    "        ][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e5a228b97042ffabffc734f95e8b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5153ad430f3b4aeeaa8473e49fecfcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/3399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = processed_datasets[\"train\"]\n",
    "eval_dataset = processed_datasets[\"test\"]\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,192 || all params: 559,222,784 || trainable%: 0.0014648902430985358\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "model = get_peft_model(model, peft_config)\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.27it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(1.5881e+12, device='cuda:0') train_epoch_loss=tensor(28.0936, device='cuda:0') eval_ppl=tensor(4344.7617, device='cuda:0') eval_epoch_loss=tensor(8.3767, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.95it/s]\n",
      "100%|██████████| 425/425 [00:56<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=tensor(2524.3499, device='cuda:0') train_epoch_loss=tensor(7.8337, device='cuda:0') eval_ppl=tensor(3467.7371, device='cuda:0') eval_epoch_loss=tensor(8.1513, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.07it/s]\n",
      "100%|██████████| 425/425 [00:56<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=tensor(504.2209, device='cuda:0') train_epoch_loss=tensor(6.2230, device='cuda:0') eval_ppl=tensor(4791.2627, device='cuda:0') eval_epoch_loss=tensor(8.4745, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.13it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: train_ppl=tensor(277.9082, device='cuda:0') train_epoch_loss=tensor(5.6273, device='cuda:0') eval_ppl=tensor(6458.5493, device='cuda:0') eval_epoch_loss=tensor(8.7732, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: train_ppl=tensor(188.8075, device='cuda:0') train_epoch_loss=tensor(5.2407, device='cuda:0') eval_ppl=tensor(6848.2998, device='cuda:0') eval_epoch_loss=tensor(8.8318, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.13it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5: train_ppl=tensor(135.5616, device='cuda:0') train_epoch_loss=tensor(4.9094, device='cuda:0') eval_ppl=tensor(8928.5869, device='cuda:0') eval_epoch_loss=tensor(9.0970, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.00it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6: train_ppl=tensor(100.9721, device='cuda:0') train_epoch_loss=tensor(4.6148, device='cuda:0') eval_ppl=tensor(11433.2734, device='cuda:0') eval_epoch_loss=tensor(9.3443, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.08it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7: train_ppl=tensor(79.3374, device='cuda:0') train_epoch_loss=tensor(4.3737, device='cuda:0') eval_ppl=tensor(22623.8750, device='cuda:0') eval_epoch_loss=tensor(10.0268, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.13it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8: train_ppl=tensor(60.7379, device='cuda:0') train_epoch_loss=tensor(4.1066, device='cuda:0') eval_ppl=tensor(16774.0879, device='cuda:0') eval_epoch_loss=tensor(9.7276, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.13it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9: train_ppl=tensor(48.4998, device='cuda:0') train_epoch_loss=tensor(3.8816, device='cuda:0') eval_ppl=tensor(21259.6699, device='cuda:0') eval_epoch_loss=tensor(9.9646, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.13it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10: train_ppl=tensor(35.3181, device='cuda:0') train_epoch_loss=tensor(3.5644, device='cuda:0') eval_ppl=tensor(225734.1406, device='cuda:0') eval_epoch_loss=tensor(12.3271, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.13it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11: train_ppl=tensor(26.0290, device='cuda:0') train_epoch_loss=tensor(3.2592, device='cuda:0') eval_ppl=tensor(2952165.2500, device='cuda:0') eval_epoch_loss=tensor(14.8980, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.84it/s]\n",
      "100%|██████████| 425/425 [00:56<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12: train_ppl=tensor(21.0054, device='cuda:0') train_epoch_loss=tensor(3.0448, device='cuda:0') eval_ppl=tensor(9176759., device='cuda:0') eval_epoch_loss=tensor(16.0322, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13: train_ppl=tensor(16.4122, device='cuda:0') train_epoch_loss=tensor(2.7980, device='cuda:0') eval_ppl=tensor(216321.5312, device='cuda:0') eval_epoch_loss=tensor(12.2845, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.01it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14: train_ppl=tensor(11.1360, device='cuda:0') train_epoch_loss=tensor(2.4102, device='cuda:0') eval_ppl=tensor(136458.6875, device='cuda:0') eval_epoch_loss=tensor(11.8238, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.04it/s]\n",
      "100%|██████████| 425/425 [00:56<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15: train_ppl=tensor(8.6281, device='cuda:0') train_epoch_loss=tensor(2.1550, device='cuda:0') eval_ppl=tensor(977228.4375, device='cuda:0') eval_epoch_loss=tensor(13.7925, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.12it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16: train_ppl=tensor(6.7098, device='cuda:0') train_epoch_loss=tensor(1.9036, device='cuda:0') eval_ppl=tensor(708188.6250, device='cuda:0') eval_epoch_loss=tensor(13.4705, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.80it/s]\n",
      "100%|██████████| 425/425 [00:59<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17: train_ppl=tensor(4.2129, device='cuda:0') train_epoch_loss=tensor(1.4381, device='cuda:0') eval_ppl=tensor(139424.4062, device='cuda:0') eval_epoch_loss=tensor(11.8453, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.81it/s]\n",
      "100%|██████████| 425/425 [00:59<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18: train_ppl=tensor(3.1764, device='cuda:0') train_epoch_loss=tensor(1.1558, device='cuda:0') eval_ppl=tensor(18920136., device='cuda:0') eval_epoch_loss=tensor(16.7557, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.92it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19: train_ppl=tensor(2.6981, device='cuda:0') train_epoch_loss=tensor(0.9925, device='cuda:0') eval_ppl=tensor(191636.7344, device='cuda:0') eval_epoch_loss=tensor(12.1634, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.96it/s]\n",
      "100%|██████████| 425/425 [00:59<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=20: train_ppl=tensor(2.1237, device='cuda:0') train_epoch_loss=tensor(0.7532, device='cuda:0') eval_ppl=tensor(71699.6797, device='cuda:0') eval_epoch_loss=tensor(11.1802, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.95it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=21: train_ppl=tensor(2.1228, device='cuda:0') train_epoch_loss=tensor(0.7527, device='cuda:0') eval_ppl=tensor(66626.4062, device='cuda:0') eval_epoch_loss=tensor(11.1069, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.14it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=22: train_ppl=tensor(2.0496, device='cuda:0') train_epoch_loss=tensor(0.7176, device='cuda:0') eval_ppl=tensor(97178.4688, device='cuda:0') eval_epoch_loss=tensor(11.4843, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.14it/s]\n",
      "100%|██████████| 425/425 [00:55<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=23: train_ppl=tensor(1.7134, device='cuda:0') train_epoch_loss=tensor(0.5385, device='cuda:0') eval_ppl=tensor(589138.7500, device='cuda:0') eval_epoch_loss=tensor(13.2864, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.14it/s]\n",
      "100%|██████████| 425/425 [00:56<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=24: train_ppl=tensor(1.5487, device='cuda:0') train_epoch_loss=tensor(0.4374, device='cuda:0') eval_ppl=tensor(62475.9922, device='cuda:0') eval_epoch_loss=tensor(11.0425, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.00it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=25: train_ppl=tensor(1.4789, device='cuda:0') train_epoch_loss=tensor(0.3913, device='cuda:0') eval_ppl=tensor(115113.5391, device='cuda:0') eval_epoch_loss=tensor(11.6537, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.94it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=26: train_ppl=tensor(1.3804, device='cuda:0') train_epoch_loss=tensor(0.3223, device='cuda:0') eval_ppl=tensor(98652.7109, device='cuda:0') eval_epoch_loss=tensor(11.4994, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.89it/s]\n",
      "100%|██████████| 425/425 [00:56<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=27: train_ppl=tensor(1.3302, device='cuda:0') train_epoch_loss=tensor(0.2854, device='cuda:0') eval_ppl=tensor(101736.6406, device='cuda:0') eval_epoch_loss=tensor(11.5301, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.11it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=28: train_ppl=tensor(1.3129, device='cuda:0') train_epoch_loss=tensor(0.2723, device='cuda:0') eval_ppl=tensor(92312.5781, device='cuda:0') eval_epoch_loss=tensor(11.4329, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.95it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=29: train_ppl=tensor(1.3197, device='cuda:0') train_epoch_loss=tensor(0.2774, device='cuda:0') eval_ppl=tensor(107999.8125, device='cuda:0') eval_epoch_loss=tensor(11.5899, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.91it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=30: train_ppl=tensor(1.2870, device='cuda:0') train_epoch_loss=tensor(0.2523, device='cuda:0') eval_ppl=tensor(114834.1484, device='cuda:0') eval_epoch_loss=tensor(11.6512, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.14it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=31: train_ppl=tensor(1.2828, device='cuda:0') train_epoch_loss=tensor(0.2491, device='cuda:0') eval_ppl=tensor(124675.4219, device='cuda:0') eval_epoch_loss=tensor(11.7335, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.99it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=32: train_ppl=tensor(1.2673, device='cuda:0') train_epoch_loss=tensor(0.2369, device='cuda:0') eval_ppl=tensor(160374.7656, device='cuda:0') eval_epoch_loss=tensor(11.9853, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.93it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=33: train_ppl=tensor(1.2342, device='cuda:0') train_epoch_loss=tensor(0.2104, device='cuda:0') eval_ppl=tensor(200293.0312, device='cuda:0') eval_epoch_loss=tensor(12.2075, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.92it/s]\n",
      "100%|██████████| 425/425 [00:59<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=34: train_ppl=tensor(1.1987, device='cuda:0') train_epoch_loss=tensor(0.1813, device='cuda:0') eval_ppl=tensor(149047.6875, device='cuda:0') eval_epoch_loss=tensor(11.9120, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.94it/s]\n",
      "100%|██████████| 425/425 [01:00<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=35: train_ppl=tensor(1.2763, device='cuda:0') train_epoch_loss=tensor(0.2440, device='cuda:0') eval_ppl=tensor(178000.4531, device='cuda:0') eval_epoch_loss=tensor(12.0895, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.93it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=36: train_ppl=tensor(1.3315, device='cuda:0') train_epoch_loss=tensor(0.2863, device='cuda:0') eval_ppl=tensor(178134.9531, device='cuda:0') eval_epoch_loss=tensor(12.0903, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.93it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=37: train_ppl=tensor(1.2641, device='cuda:0') train_epoch_loss=tensor(0.2344, device='cuda:0') eval_ppl=tensor(440663.3750, device='cuda:0') eval_epoch_loss=tensor(12.9960, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.94it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=38: train_ppl=tensor(1.2272, device='cuda:0') train_epoch_loss=tensor(0.2047, device='cuda:0') eval_ppl=tensor(207645.0938, device='cuda:0') eval_epoch_loss=tensor(12.2436, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.96it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=39: train_ppl=tensor(1.1871, device='cuda:0') train_epoch_loss=tensor(0.1715, device='cuda:0') eval_ppl=tensor(196149.4531, device='cuda:0') eval_epoch_loss=tensor(12.1866, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.96it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=40: train_ppl=tensor(1.2421, device='cuda:0') train_epoch_loss=tensor(0.2168, device='cuda:0') eval_ppl=tensor(149386.2344, device='cuda:0') eval_epoch_loss=tensor(11.9143, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.95it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=41: train_ppl=tensor(1.3589, device='cuda:0') train_epoch_loss=tensor(0.3067, device='cuda:0') eval_ppl=tensor(144990.1875, device='cuda:0') eval_epoch_loss=tensor(11.8844, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.99it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=42: train_ppl=tensor(1.1975, device='cuda:0') train_epoch_loss=tensor(0.1803, device='cuda:0') eval_ppl=tensor(155364.9688, device='cuda:0') eval_epoch_loss=tensor(11.9535, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.95it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=43: train_ppl=tensor(1.2062, device='cuda:0') train_epoch_loss=tensor(0.1874, device='cuda:0') eval_ppl=tensor(136195.7969, device='cuda:0') eval_epoch_loss=tensor(11.8218, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.80it/s]\n",
      "100%|██████████| 425/425 [00:58<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=44: train_ppl=tensor(1.1909, device='cuda:0') train_epoch_loss=tensor(0.1747, device='cuda:0') eval_ppl=tensor(180744.6094, device='cuda:0') eval_epoch_loss=tensor(12.1048, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.95it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=45: train_ppl=tensor(1.2460, device='cuda:0') train_epoch_loss=tensor(0.2200, device='cuda:0') eval_ppl=tensor(165565.2031, device='cuda:0') eval_epoch_loss=tensor(12.0171, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.94it/s]\n",
      "100%|██████████| 425/425 [00:59<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=46: train_ppl=tensor(1.2557, device='cuda:0') train_epoch_loss=tensor(0.2277, device='cuda:0') eval_ppl=tensor(131692.2812, device='cuda:0') eval_epoch_loss=tensor(11.7882, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.86it/s]\n",
      "100%|██████████| 425/425 [00:59<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=47: train_ppl=tensor(1.2086, device='cuda:0') train_epoch_loss=tensor(0.1895, device='cuda:0') eval_ppl=tensor(146697.7500, device='cuda:0') eval_epoch_loss=tensor(11.8961, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.80it/s]\n",
      "100%|██████████| 425/425 [01:00<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=48: train_ppl=tensor(1.1671, device='cuda:0') train_epoch_loss=tensor(0.1545, device='cuda:0') eval_ppl=tensor(158958.5000, device='cuda:0') eval_epoch_loss=tensor(11.9764, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  3.67it/s]\n",
      "100%|██████████| 425/425 [00:57<00:00,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=49: train_ppl=tensor(1.1522, device='cuda:0') train_epoch_loss=tensor(0.1417, device='cuda:0') eval_ppl=tensor(162381.3125, device='cuda:0') eval_epoch_loss=tensor(11.9977, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978e6f6539d64077918eae6c0cb06c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\4475358\\.conda\\envs\\prompt-tuning-p310\\lib\\site-packages\\transformers\\utils\\hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468b08726bd443d5b35ce5568d0b84a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/32.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/grasool/bloomz-560m_PROMPT_TUNING_CAUSAL_LM/commit/25dd3d6b94e5e71cde9acaeed33f52fe62ba2ddd', commit_message='Upload model', commit_description='', oid='25dd3d6b94e5e71cde9acaeed33f52fe62ba2ddd', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_id = \"grasool/bloomz-560m_PROMPT_TUNING_CAUSAL_LM\"\n",
    "model.push_to_hub(\"grasool/bloomz-560m_PROMPT_TUNING_CAUSAL_LM\", token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-tuning-p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
